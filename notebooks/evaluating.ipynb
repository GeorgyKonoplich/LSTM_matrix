{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 10\n",
    "\n",
    "gpu_id='gpu0'\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=\"+gpu_id +\",lib.cnmem=1\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers.advanced_activations import SReLU\n",
    "from keras import callbacks as ckbs\n",
    "import random\n",
    "import time\n",
    "import gzip\n",
    "from keras.models import model_from_json\n",
    "import pickle as pkl\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from docutils.languages.af import labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_neural_network(file_from):\n",
    "    (nn_arch, nn_weights_path) = pkl.load(open(file_from, 'rb'))\n",
    "    nn = model_from_json(nn_arch)\n",
    "    nn.set_weights(nn_weights_path)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = gzip.open('../data/processed/pkl_short/embeddings.pkl.gz', 'rb')\n",
    "embeddings = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "label2Idx = embeddings['label2Idx']\n",
    "\n",
    "#Inverse label mapping\n",
    "idx2Label = {v: k for k, v in label2Idx.items()}\n",
    "\n",
    "f = gzip.open('../data/processed/pkl/data.pkl.gz', 'rb')\n",
    "test_data = pkl.load(f)\n",
    "dev_data = pkl.load(f)\n",
    "wiki_data = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "n_out = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullModelCheckpoint(ckbs.ModelCheckpoint):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "        if self.save_best_only:\n",
    "            current = logs.get(self.monitor)\n",
    "            if current is None:\n",
    "                warnings.warn('Can save best model only with %s available, '\n",
    "                              'skipping.' % (self.monitor), RuntimeWarning)\n",
    "            else:\n",
    "                if self.monitor_op(current, self.best):\n",
    "                    if self.verbose > 0:\n",
    "                        print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                              ' saving model to %s'\n",
    "                              % (epoch, self.monitor, self.best,\n",
    "                                 current, filepath))\n",
    "                    self.best = current\n",
    "                    pkl.dump([self.model.to_json(), self.model.get_weights()], open(filepath, 'wb'))\n",
    "                else:\n",
    "                    if self.verbose > 0:\n",
    "                        print('Epoch %05d: %s did not improve' %\n",
    "                              (epoch, self.monitor))\n",
    "        else:\n",
    "            if self.verbose > 0:\n",
    "                print('Epoch %05d: saving model to %s' % (epoch, filepath))\n",
    "            pkl.dump([self.model.to_json(), self.model.get_weights()], open(filepath, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(matrix, matrix_test):\n",
    "    emb_layers = []\n",
    "    for param_num in range(matrix.shape[2]):\n",
    "        model = Sequential()\n",
    "        emd_max1 = np.max(matrix[:, :, param_num]) + 2\n",
    "        emd_max = np.max(matrix_test[:, :, param_num]) + 2\n",
    "        if emd_max > emd_max1:\n",
    "            embedding_max_index = emd_max\n",
    "        else:\n",
    "            embedding_max_index = emd_max1\n",
    "        out_size = 3\n",
    "        if embedding_max_index > 300:\n",
    "            out_size = 300\n",
    "        elif embedding_max_index > 100:\n",
    "            out_size = 10\n",
    "        model.add(Embedding(embedding_max_index, out_size, input_length=matrix.shape[1]))\n",
    "        emb_layers.append(model)\n",
    "    \n",
    "    merged = Merge(emb_layers, mode = 'concat')\n",
    "    return merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    print( \"%d test size\" % len(data))\n",
    "    data = np.array(data)\n",
    "    print(data.shape)\n",
    "    X = [x[0] for x in data]\n",
    "    y = [x[1][0] for x in data]\n",
    "    return np.array(X), np.array(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_train_val_test_split(matrix, target, number_of_samples_to_use=None, test_size=0.2, random_state=23):\n",
    "   \n",
    "    train_samples = int(matrix.shape[0]*1)\n",
    "    X_train = matrix[:train_samples]\n",
    "    X_test = matrix[train_samples:]\n",
    "        \n",
    "    y_train = target[:train_samples]\n",
    "    y_test = target[train_samples:]\n",
    "        \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=random_state)\n",
    "    print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "    \n",
    "    \n",
    "    return  [X_train[:,:,i] for i in range(X_train.shape[2])], \\\n",
    "            [X_val[:,:,i] for i in range(X_val.shape[2])], \\\n",
    "            y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_model(X, X_test, name):\n",
    "    merged = get_model(X, X_test)\n",
    "    model = Sequential()\n",
    "    model.add(merged)\n",
    "    #model.add(LSTM(100, return_sequences=True, dropout_W=0.2))\n",
    "    #model.add(LSTM(100, return_sequences=True, dropout_W=0.2))\n",
    "    model.add(LSTM(100, dropout_W=0.25))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(100))\n",
    "    #model.add(SReLU())\n",
    "    model.add(Dense(n_out, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-7, momentum=0.0, nesterov=False, clipvalue=3) \n",
    "    rmsprop = RMSprop(clipvalue=3) \n",
    "    nadam = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=nadam,metrics=['accuracy', 'precision', 'recall', 'categorical_accuracy', 'fmeasure'])\n",
    "\n",
    "    #model.summary()\n",
    "    checkpointer = FullModelCheckpoint(filepath= \"../models/\" + name, verbose=1, save_best_only=True)\n",
    "    return model, checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31017 test size\n",
      "(31017, 2)\n",
      "59381 test size\n",
      "(59381, 2)\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data(dev_data)\n",
    "X_test, y_test = get_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24813, 33, 25) (6204, 33, 25) (0, 33, 25) (24813,) (6204,) (0,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = matrix_train_val_test_split(X, y)\n",
    "y_train_dum = OneHotEncoder(sparse=False).fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_dum = OneHotEncoder(sparse=False).fit_transform(y_val.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model, checkpointer = get_full_model(X, X_test, \"new5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24813 samples, validate on 6204 samples\n",
      "Epoch 1/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.8722 - precision: 0.8814 - recall: 0.8587 - categorical_accuracy: 0.8722 - fmeasure: 0.8693Epoch 00000: val_loss improved from inf to 0.34991, saving model to ../models/new5\n",
      "24813/24813 [==============================] - 56s - loss: 0.4333 - acc: 0.8721 - precision: 0.8813 - recall: 0.8586 - categorical_accuracy: 0.8721 - fmeasure: 0.8692 - val_loss: 0.3499 - val_acc: 0.8851 - val_precision: 0.8931 - val_recall: 0.8749 - val_categorical_accuracy: 0.8851 - val_fmeasure: 0.8838\n",
      "Epoch 2/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9401 - precision: 0.9481 - recall: 0.9325 - categorical_accuracy: 0.9401 - fmeasure: 0.9401Epoch 00001: val_loss improved from 0.34991 to 0.15436, saving model to ../models/new5\n",
      "24813/24813 [==============================] - 56s - loss: 0.1677 - acc: 0.9402 - precision: 0.9482 - recall: 0.9325 - categorical_accuracy: 0.9402 - fmeasure: 0.9401 - val_loss: 0.1544 - val_acc: 0.9513 - val_precision: 0.9564 - val_recall: 0.9473 - val_categorical_accuracy: 0.9513 - val_fmeasure: 0.9517\n",
      "Epoch 3/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9899 - precision: 0.9903 - recall: 0.9891 - categorical_accuracy: 0.9899 - fmeasure: 0.9897Epoch 00002: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0314 - acc: 0.9899 - precision: 0.9903 - recall: 0.9891 - categorical_accuracy: 0.9899 - fmeasure: 0.9897 - val_loss: 0.1621 - val_acc: 0.9478 - val_precision: 0.9488 - val_recall: 0.9462 - val_categorical_accuracy: 0.9478 - val_fmeasure: 0.9475\n",
      "Epoch 4/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9974 - precision: 0.9975 - recall: 0.9973 - categorical_accuracy: 0.9974 - fmeasure: 0.9974Epoch 00003: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0089 - acc: 0.9974 - precision: 0.9975 - recall: 0.9973 - categorical_accuracy: 0.9974 - fmeasure: 0.9974 - val_loss: 0.1648 - val_acc: 0.9581 - val_precision: 0.9587 - val_recall: 0.9570 - val_categorical_accuracy: 0.9581 - val_fmeasure: 0.9578\n",
      "Epoch 5/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990 - precision: 0.9991 - recall: 0.9990 - categorical_accuracy: 0.9990 - fmeasure: 0.9990Epoch 00004: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0038 - acc: 0.9990 - precision: 0.9991 - recall: 0.9990 - categorical_accuracy: 0.9990 - fmeasure: 0.9990 - val_loss: 0.1809 - val_acc: 0.9547 - val_precision: 0.9558 - val_recall: 0.9545 - val_categorical_accuracy: 0.9547 - val_fmeasure: 0.9551\n",
      "Epoch 6/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991 - precision: 0.9992 - recall: 0.9990 - categorical_accuracy: 0.9991 - fmeasure: 0.9991Epoch 00005: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0035 - acc: 0.9991 - precision: 0.9992 - recall: 0.9990 - categorical_accuracy: 0.9991 - fmeasure: 0.9991 - val_loss: 0.2106 - val_acc: 0.9544 - val_precision: 0.9550 - val_recall: 0.9541 - val_categorical_accuracy: 0.9544 - val_fmeasure: 0.9545\n",
      "Epoch 7/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981 - precision: 0.9982 - recall: 0.9980 - categorical_accuracy: 0.9981 - fmeasure: 0.9981Epoch 00006: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0063 - acc: 0.9981 - precision: 0.9982 - recall: 0.9980 - categorical_accuracy: 0.9981 - fmeasure: 0.9981 - val_loss: 0.1872 - val_acc: 0.9513 - val_precision: 0.9527 - val_recall: 0.9491 - val_categorical_accuracy: 0.9513 - val_fmeasure: 0.9508\n",
      "Epoch 8/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9989 - precision: 0.9990 - recall: 0.9988 - categorical_accuracy: 0.9989 - fmeasure: 0.9989Epoch 00007: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0035 - acc: 0.9989 - precision: 0.9990 - recall: 0.9988 - categorical_accuracy: 0.9989 - fmeasure: 0.9989 - val_loss: 0.1953 - val_acc: 0.9578 - val_precision: 0.9585 - val_recall: 0.9571 - val_categorical_accuracy: 0.9578 - val_fmeasure: 0.9578\n",
      "Epoch 9/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9994 - precision: 0.9994 - recall: 0.9994 - categorical_accuracy: 0.9994 - fmeasure: 0.9994Epoch 00008: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0020 - acc: 0.9994 - precision: 0.9994 - recall: 0.9994 - categorical_accuracy: 0.9994 - fmeasure: 0.9994 - val_loss: 0.2100 - val_acc: 0.9539 - val_precision: 0.9549 - val_recall: 0.9528 - val_categorical_accuracy: 0.9539 - val_fmeasure: 0.9538\n",
      "Epoch 10/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991 - precision: 0.9991 - recall: 0.9991 - categorical_accuracy: 0.9991 - fmeasure: 0.9991Epoch 00009: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0037 - acc: 0.9991 - precision: 0.9991 - recall: 0.9991 - categorical_accuracy: 0.9991 - fmeasure: 0.9991 - val_loss: 0.2017 - val_acc: 0.9566 - val_precision: 0.9579 - val_recall: 0.9560 - val_categorical_accuracy: 0.9566 - val_fmeasure: 0.9569\n",
      "Epoch 11/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9988 - precision: 0.9988 - recall: 0.9988 - categorical_accuracy: 0.9988 - fmeasure: 0.9988Epoch 00010: val_loss did not improve\n",
      "24813/24813 [==============================] - 56s - loss: 0.0035 - acc: 0.9988 - precision: 0.9988 - recall: 0.9988 - categorical_accuracy: 0.9988 - fmeasure: 0.9988 - val_loss: 0.2002 - val_acc: 0.9537 - val_precision: 0.9550 - val_recall: 0.9536 - val_categorical_accuracy: 0.9537 - val_fmeasure: 0.9543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bd760a908>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train_dum, batch_size=32, nb_epoch=11, validation_data=(X_val, y_val_dum), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
