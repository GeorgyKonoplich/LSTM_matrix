{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 10\n",
    "\n",
    "gpu_id='gpu0'\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=\"+gpu_id +\",lib.cnmem=1\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers.advanced_activations import SReLU\n",
    "from keras import callbacks as ckbs\n",
    "import random\n",
    "import time\n",
    "import gzip\n",
    "from keras.models import model_from_json\n",
    "import pickle as pkl\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from docutils.languages.af import labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_neural_network(file_from):\n",
    "    (nn_arch, nn_weights_path) = pkl.load(open(file_from, 'rb'))\n",
    "    nn = model_from_json(nn_arch)\n",
    "    nn.set_weights(nn_weights_path)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = gzip.open('../data/processed/pkl_short/embeddings.pkl.gz', 'rb')\n",
    "embeddings = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "label2Idx = embeddings['label2Idx']\n",
    "\n",
    "#Inverse label mapping\n",
    "idx2Label = {v: k for k, v in label2Idx.items()}\n",
    "\n",
    "f = gzip.open('../data/processed/pkl/data.pkl.gz', 'rb')\n",
    "test_data = pkl.load(f)\n",
    "dev_data = pkl.load(f)\n",
    "wiki_data = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "n_out = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullModelCheckpoint(ckbs.ModelCheckpoint):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "        if self.save_best_only:\n",
    "            current = logs.get(self.monitor)\n",
    "            if current is None:\n",
    "                warnings.warn('Can save best model only with %s available, '\n",
    "                              'skipping.' % (self.monitor), RuntimeWarning)\n",
    "            else:\n",
    "                if self.monitor_op(current, self.best):\n",
    "                    if self.verbose > 0:\n",
    "                        print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                              ' saving model to %s'\n",
    "                              % (epoch, self.monitor, self.best,\n",
    "                                 current, filepath))\n",
    "                    self.best = current\n",
    "                    pkl.dump([self.model.to_json(), self.model.get_weights()], open(filepath, 'wb'))\n",
    "                else:\n",
    "                    if self.verbose > 0:\n",
    "                        print('Epoch %05d: %s did not improve' %\n",
    "                              (epoch, self.monitor))\n",
    "        else:\n",
    "            if self.verbose > 0:\n",
    "                print('Epoch %05d: saving model to %s' % (epoch, filepath))\n",
    "            pkl.dump([self.model.to_json(), self.model.get_weights()], open(filepath, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(matrix, matrix_test):\n",
    "    emb_layers = []\n",
    "    for param_num in range(matrix.shape[2]):\n",
    "        model = Sequential()\n",
    "        emd_max1 = np.max(matrix[:, :, param_num]) + 2\n",
    "        emd_max = np.max(matrix_test[:, :, param_num]) + 2\n",
    "        if emd_max > emd_max1:\n",
    "            embedding_max_index = emd_max\n",
    "        else:\n",
    "            embedding_max_index = emd_max1\n",
    "        out_size = 3\n",
    "        if embedding_max_index > 300:\n",
    "            out_size = 300\n",
    "        elif embedding_max_index > 100:\n",
    "            out_size = 10\n",
    "        model.add(Embedding(embedding_max_index, out_size, input_length=matrix.shape[1]))\n",
    "        emb_layers.append(model)\n",
    "    \n",
    "    merged = Merge(emb_layers, mode = 'concat')\n",
    "    return merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    print( \"%d test size\" % len(data))\n",
    "    data = np.array(data)\n",
    "    print(data.shape)\n",
    "    X = [x[0] for x in data]\n",
    "    y = [x[1][0] for x in data]\n",
    "    return np.array(X), np.array(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_train_val_test_split(matrix, target, number_of_samples_to_use=None, test_size=0.2, random_state=23):\n",
    "   \n",
    "    train_samples = int(matrix.shape[0]*1)\n",
    "    X_train = matrix[:train_samples]\n",
    "    X_test = matrix[train_samples:]\n",
    "        \n",
    "    y_train = target[:train_samples]\n",
    "    y_test = target[train_samples:]\n",
    "        \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=random_state)\n",
    "    print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "    \n",
    "    \n",
    "    return  [X_train[:,:,i] for i in range(X_train.shape[2])], \\\n",
    "            [X_val[:,:,i] for i in range(X_val.shape[2])], \\\n",
    "            y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_model(X, X_test, name):\n",
    "    merged = get_model(X, X_test)\n",
    "    model = Sequential()\n",
    "    model.add(merged)\n",
    "    #model.add(LSTM(100, return_sequences=True, dropout_W=0.2))\n",
    "    #model.add(LSTM(100, return_sequences=True, dropout_W=0.2))\n",
    "    model.add(LSTM(150, dropout_W=0.25))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(100))\n",
    "    #model.add(SReLU())\n",
    "    model.add(Dense(n_out, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-7, momentum=0.0, nesterov=False, clipvalue=3) \n",
    "    rmsprop = RMSprop(clipvalue=3) \n",
    "    nadam = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=nadam,metrics=['accuracy', 'precision', 'recall', 'categorical_accuracy', 'fmeasure'])\n",
    "\n",
    "    #model.summary()\n",
    "    checkpointer = FullModelCheckpoint(filepath= \"../models/\" + name, verbose=1, save_best_only=True)\n",
    "    return model, checkpointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31017 test size\n",
      "(31017, 2)\n",
      "59381 test size\n",
      "(59381, 2)\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data(dev_data)\n",
    "X_test, y_test = get_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24813, 33, 25) (6204, 33, 25) (0, 33, 25) (24813,) (6204,) (0,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = matrix_train_val_test_split(X, y)\n",
    "y_train_dum = OneHotEncoder(sparse=False).fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_dum = OneHotEncoder(sparse=False).fit_transform(y_val.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model, checkpointer = get_full_model(X, X_test, \"new6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24813 samples, validate on 6204 samples\n",
      "Epoch 1/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.4230 - acc: 0.8751 - precision: 0.8852 - recall: 0.8619 - categorical_accuracy: 0.8751 - fmeasure: 0.8729Epoch 00000: val_loss improved from inf to 0.30398, saving model to ../models/new6\n",
      "24813/24813 [==============================] - 59s - loss: 0.4230 - acc: 0.8751 - precision: 0.8852 - recall: 0.8619 - categorical_accuracy: 0.8751 - fmeasure: 0.8729 - val_loss: 0.3040 - val_acc: 0.8993 - val_precision: 0.9116 - val_recall: 0.8877 - val_categorical_accuracy: 0.8993 - val_fmeasure: 0.8993\n",
      "Epoch 2/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9561 - precision: 0.9629 - recall: 0.9500 - categorical_accuracy: 0.9561 - fmeasure: 0.9563Epoch 00001: val_loss improved from 0.30398 to 0.15246, saving model to ../models/new6\n",
      "24813/24813 [==============================] - 59s - loss: 0.1287 - acc: 0.9561 - precision: 0.9629 - recall: 0.9501 - categorical_accuracy: 0.9561 - fmeasure: 0.9563 - val_loss: 0.1525 - val_acc: 0.9479 - val_precision: 0.9552 - val_recall: 0.9446 - val_categorical_accuracy: 0.9479 - val_fmeasure: 0.9497\n",
      "Epoch 3/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9905 - precision: 0.9909 - recall: 0.9900 - categorical_accuracy: 0.9905 - fmeasure: 0.9905Epoch 00002: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0292 - acc: 0.9905 - precision: 0.9909 - recall: 0.9900 - categorical_accuracy: 0.9905 - fmeasure: 0.9905 - val_loss: 0.1581 - val_acc: 0.9521 - val_precision: 0.9547 - val_recall: 0.9513 - val_categorical_accuracy: 0.9521 - val_fmeasure: 0.9530\n",
      "Epoch 4/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9973 - precision: 0.9974 - recall: 0.9972 - categorical_accuracy: 0.9973 - fmeasure: 0.9973Epoch 00003: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0093 - acc: 0.9973 - precision: 0.9974 - recall: 0.9972 - categorical_accuracy: 0.9973 - fmeasure: 0.9973 - val_loss: 0.1644 - val_acc: 0.9592 - val_precision: 0.9603 - val_recall: 0.9579 - val_categorical_accuracy: 0.9592 - val_fmeasure: 0.9591\n",
      "Epoch 5/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9981 - precision: 0.9982 - recall: 0.9981 - categorical_accuracy: 0.9981 - fmeasure: 0.9982Epoch 00004: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0053 - acc: 0.9981 - precision: 0.9982 - recall: 0.9981 - categorical_accuracy: 0.9981 - fmeasure: 0.9982 - val_loss: 0.1795 - val_acc: 0.9508 - val_precision: 0.9528 - val_recall: 0.9494 - val_categorical_accuracy: 0.9508 - val_fmeasure: 0.9511\n",
      "Epoch 6/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9983 - precision: 0.9983 - recall: 0.9982 - categorical_accuracy: 0.9983 - fmeasure: 0.9983Epoch 00005: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0054 - acc: 0.9983 - precision: 0.9983 - recall: 0.9982 - categorical_accuracy: 0.9983 - fmeasure: 0.9983 - val_loss: 0.1936 - val_acc: 0.9592 - val_precision: 0.9609 - val_recall: 0.9581 - val_categorical_accuracy: 0.9592 - val_fmeasure: 0.9595\n",
      "Epoch 7/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9984 - precision: 0.9985 - recall: 0.9983 - categorical_accuracy: 0.9984 - fmeasure: 0.9984Epoch 00006: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0052 - acc: 0.9984 - precision: 0.9985 - recall: 0.9983 - categorical_accuracy: 0.9984 - fmeasure: 0.9984 - val_loss: 0.1971 - val_acc: 0.9599 - val_precision: 0.9607 - val_recall: 0.9591 - val_categorical_accuracy: 0.9599 - val_fmeasure: 0.9599\n",
      "Epoch 8/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990 - precision: 0.9990 - recall: 0.9990 - categorical_accuracy: 0.9990 - fmeasure: 0.9990Epoch 00007: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0036 - acc: 0.9990 - precision: 0.9990 - recall: 0.9990 - categorical_accuracy: 0.9990 - fmeasure: 0.9990 - val_loss: 0.1802 - val_acc: 0.9591 - val_precision: 0.9603 - val_recall: 0.9583 - val_categorical_accuracy: 0.9591 - val_fmeasure: 0.9593\n",
      "Epoch 9/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9986 - precision: 0.9986 - recall: 0.9986 - categorical_accuracy: 0.9986 - fmeasure: 0.9986Epoch 00008: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0050 - acc: 0.9986 - precision: 0.9986 - recall: 0.9986 - categorical_accuracy: 0.9986 - fmeasure: 0.9986 - val_loss: 0.1929 - val_acc: 0.9581 - val_precision: 0.9587 - val_recall: 0.9571 - val_categorical_accuracy: 0.9581 - val_fmeasure: 0.9579\n",
      "Epoch 10/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9986 - precision: 0.9987 - recall: 0.9986 - categorical_accuracy: 0.9986 - fmeasure: 0.9986Epoch 00009: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0044 - acc: 0.9986 - precision: 0.9986 - recall: 0.9985 - categorical_accuracy: 0.9986 - fmeasure: 0.9986 - val_loss: 0.2198 - val_acc: 0.9500 - val_precision: 0.9512 - val_recall: 0.9489 - val_categorical_accuracy: 0.9500 - val_fmeasure: 0.9500\n",
      "Epoch 11/11\n",
      "24800/24813 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986 - precision: 0.9987 - recall: 0.9985 - categorical_accuracy: 0.9986 - fmeasure: 0.9986Epoch 00010: val_loss did not improve\n",
      "24813/24813 [==============================] - 58s - loss: 0.0041 - acc: 0.9986 - precision: 0.9987 - recall: 0.9985 - categorical_accuracy: 0.9986 - fmeasure: 0.9986 - val_loss: 0.2057 - val_acc: 0.9565 - val_precision: 0.9570 - val_recall: 0.9554 - val_categorical_accuracy: 0.9565 - val_fmeasure: 0.9562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0be3049588>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train_dum, batch_size=32, nb_epoch=11, validation_data=(X_val, y_val_dum), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keras_gridsearch(network_topology, branches, \\\n",
    "                     X_train, y_train, \\\n",
    "                     X_val, y_val, \\\n",
    "                     X_test, y_test, \\\n",
    "                     params, fit_params, \\\n",
    "                     save_best_model=None, \\\n",
    "                     save_results=None, start=None, end=None\n",
    "                     ):\n",
    "    from keras.wrappers.scikit_learn import KerasClassifier\n",
    "    results = []\n",
    "    best_score = 0\n",
    "    best_model = 0\n",
    "\n",
    "    for param in list(ParameterGrid(params))[start:end]:\n",
    "        try:\n",
    "            keras_model = KerasClassifier(build_fn=network_topology, branches=branches, **param)\n",
    "            keras_model.fit(X_train, y_train, **fit_params)\n",
    "            stats_val = get_stats(keras_model, X_val, y_val)\n",
    "            stats_test = get_stats(keras_model, X_test, y_test)\n",
    "            results.append((param, stats_val, stats_test))\n",
    "\n",
    "            if best_score <= stats_val['f1']:\n",
    "                best_score = stats_val['f1']\n",
    "                best_model = keras_model\n",
    "            \n",
    "                if save_best_model != None:\n",
    "                    save_keras_model(best_model.model, save_best_model)\n",
    "                if save_results != None:\n",
    "                    pickle.dump(results, open(save_results, 'wb'))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "                    \n",
    "    return results, best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lstm_layers' :[[100, 100, 100], [150, 100]],\n",
    "    'dense_layers': [[100, 100], [100]],\n",
    "    'loss': ['categorical_crossentropy'],\n",
    "    'activation': ['srelu', 'prelu', 'elu'],\n",
    "    'optimizer': 'Adam'],\n",
    "    'metrics': [f1],\n",
    "    'dropout': [0.25]\n",
    " }\n",
    "\n",
    "fit_params = {\n",
    "    'nb_epoch': 100,\n",
    "    'batch_size': 3072,\n",
    "    'verbose': 2,\n",
    "    'callbacks': [EarlyStopping(monitor='val_loss', patience=5)],\n",
    "    'validation_data': [X_val, y_val]\n",
    "}  \n",
    "branches = create_embedding_with_w2v_matrix(matrix, w2v_weights)\n",
    "results, best_model, best_score = keras_gridsearch(\n",
    "                      create_stacked_lstm, \\\n",
    "                      branches, \\\n",
    "                      X_train, y_train, \\\n",
    "                      X_val, y_val, \\\n",
    "                      X_test, y_test, \\\n",
    "                      params, fit_params, \\\n",
    "                      save_best_model=BEST_MODEL,\n",
    "                      save_results=RESULTS, start=0, end=12\n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
